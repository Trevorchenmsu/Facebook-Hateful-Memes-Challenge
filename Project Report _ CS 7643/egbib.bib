@misc{a_vaswani2017attention,
      title={Attention Is All You Need}, 
      author={Ashish Vaswani and Noam Shazeer and Niki Parmar and Jakob Uszkoreit and Llion Jones and Aidan N. Gomez and Lukasz Kaiser and Illia Polosukhin},
      year={2017},
      eprint={1706.03762},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{b_li2019visualbert,
      title={VisualBERT: A Simple and Performant Baseline for Vision and Language}, 
      author={Liunian Harold Li and Mark Yatskar and Da Yin and Cho-Jui Hsieh and Kai-Wei Chang},
      year={2019},
      eprint={1908.03557},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{c_gebru2020datasheets,
      title={Datasheets for Datasets}, 
      author={Timnit Gebru and Jamie Morgenstern and Briana Vecchione and Jennifer Wortman Vaughan and Hanna Wallach and Hal Daum√© III au2 and Kate Crawford},
      year={2020},
      eprint={1803.09010},
      archivePrefix={arXiv},
      primaryClass={cs.DB}
}

@misc{d_kiela2021hateful,
      title={The Hateful Memes Challenge: Detecting Hate Speech in Multimodal Memes}, 
      author={Douwe Kiela and Hamed Firooz and Aravind Mohan and Vedanuj Goswami and Amanpreet Singh and Pratik Ringshia and Davide Testuggine},
      year={2021},
      eprint={2005.04790},
      archivePrefix={arXiv},
      primaryClass={cs.AI}
}

@misc{e_velioglu2020detecting,
      title={Detecting Hate Speech in Memes Using Multimodal Deep Learning Approaches: Prize-winning solution to Hateful Memes Challenge}, 
      author={Riza Velioglu and Jewgeni Rose},
      year={2020},
      eprint={2012.12975},
      archivePrefix={arXiv},
      primaryClass={cs.AI}
}

@misc{f_zhu2020enhance,
      title={Enhance Multimodal Transformer With External Label And In-Domain Pretrain: Hateful Meme Challenge Winning Solution}, 
      author={Ron Zhu},
      year={2020},
      eprint={2012.08290},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{g_kiela2021hateful,
      title={The Hateful Memes Challenge: Detecting Hate Speech in Multimodal Memes}, 
      author={Douwe Kiela and Hamed Firooz and Aravind Mohan and Vedanuj Goswami and Amanpreet Singh and Pratik Ringshia and Davide Testuggine},
      year={2021},
      eprint={2005.04790},
      archivePrefix={arXiv},
      primaryClass={cs.AI}
}

@misc{h_keskar2017largebatch,
      title={On Large-Batch Training for Deep Learning: Generalization Gap and Sharp Minima}, 
      author={Nitish Shirish Keskar and Dheevatsa Mudigere and Jorge Nocedal and Mikhail Smelyanskiy and Ping Tak Peter Tang},
      year={2017},
      eprint={1609.04836},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}
@misc{i_Authors14,
 author = {Authors},
 title = {The frobnicatable foo filter},
 link = {https://stats.stackexchange.com/questions/164876/what-is-the-trade-off-between-batch-size-and-number-of-iterations-to-train-a-neu},
 note = {What is the trade-off between batch size and number of iterations to train a neural network?},
 year = 2015
}

@misc{i_Authors14b,
 author = {Authors},
 title = {ResNet-152},
 note = {ResNet-152 Pre-trained Model for PyTorch}
}

@misc{i_Authors14c,
 author = {Authors},
 title = {ResNet-101},
 note = {ResNet-101 Pre-trained Model for PyTorch}
}