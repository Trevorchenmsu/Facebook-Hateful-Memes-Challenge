{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "V2_GCP.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Trevorchenmsu/Facebook-Hateful-Memes-Challenge/blob/main/V2_GCP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hg5Kv3gGC0H1"
      },
      "source": [
        "# install tensorboard package\n",
        "!pip install tensorboard"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0sHeupBwC0IE",
        "outputId": "020708bb-b88a-41b8-edee-27ce513d72cc"
      },
      "source": [
        "# check the files in home folder\n",
        "import os\n",
        "import numpy\n",
        "import torch\n",
        "from torch.utils import tensorboard\n",
        "os.environ['MKL_THREADING_LAYER'] = 'GNU'\n",
        "os.environ['OC_DISABLE_DOT_ACCESS_WARNING']='1'\n",
        "home = \"/home/jishengchenmsu\"\n",
        "os.chdir(home)\n",
        "os.getcwd()\n",
        "# # check the number of images\n",
        "!ls /home/jishengchenmsu "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "FB_V0.ipynb\t       features_101\t\t  images_folder\r\n",
            "X-152-32x8d-IN5k.pkl   features_grid_extract\t  imgs_features_download.ipynb\r\n",
            "anaconda3\t       features_grid_extract.zip  mmf\r\n",
            "feature_extract.ipynb  grid-feats-vqa\t\t  vqa-maskrcnn-benchmark\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZLSCxZpC0IF"
      },
      "source": [
        "# Install specified versions of `torch` and `torchvision`, before installing mmf (causes an issue)\n",
        "!pip install torch==1.6.0 torchvision==0.7.0 -f https://download.pytorch.org/whl/torch_stable.html"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ly2j2ha-C0IG"
      },
      "source": [
        "# Install MMF from source. Clone the following repo where mmf does not \n",
        "# install default image features, since we will use our own features\n",
        "!git clone --branch no_feats --config core.symlinks=true https://github.com/rizavelioglu/mmf.git"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tTFPcdEpC0IH"
      },
      "source": [
        "# install mmf\n",
        "os.chdir(os.path.join(home, \"mmf\"))\n",
        "!pip install --editable .\n",
        "!ls /home/jishengchenmsu/mmf"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PP7NI3hRasmP"
      },
      "source": [
        "# install gdonw so that we can download files from google drive\n",
        "!pip install gdown"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "ZT3WVFakI-sJ",
        "outputId": "cfd52fb6-b8de-4ddb-d234-148df7a0fb3e"
      },
      "source": [
        "# download the zip file from the link, but it doesn not work\n",
        "img_orc_dir = \"images_folder\"\n",
        "os.chdir(os.path.join(home, img_orc_dir))\n",
        "!gdown https://drive.google.com/uc?id=1fs4wH5M51Zjs1IDRXGxLMPDtlYDhy9iT"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1fs4wH5M51Zjs1IDRXGxLMPDtlYDhy9iT\n",
            "To: /home/jishengchenmsu/images_folder/img_ocr.zip\n",
            "3.65GB [00:24, 152MB/s] \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WdjNORiQdUat",
        "outputId": "84eb6788-29f9-47fb-fc25-96f7d4b4bb5c"
      },
      "source": [
        "# convert the zip file under this path\n",
        "import os\n",
        "img_orc_dir = \"images_folder\"\n",
        "os.chdir(os.path.join(home, img_orc_dir))\n",
        "os.environ['MKL_THREADING_LAYER'] = 'GNU'\n",
        "!mmf_convert_hm --zip_file=\"img_ocr.zip\"  --password=\"\" --bypass_checksum 1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data folder is /home/jishengchenmsu/.cache/torch/mmf/data\n",
            "Zip path is img_ocr.zip\n",
            "Copying img_ocr.zip\n",
            "Unzipping img_ocr.zip\n",
            "Extracting the zip can take time. Sit back and relax.\n",
            "Moving train.jsonl\n",
            "Moving dev_seen.jsonl\n",
            "Moving test_seen.jsonl\n",
            "Moving dev_unseen.jsonl\n",
            "Moving test_unseen.jsonl\n",
            "Moving img\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "soJiNT6MysMx",
        "outputId": "d36e5e7b-47c2-4966-83a1-c40f4203ed7f"
      },
      "source": [
        "# check the files under the cach folder\n",
        "!ls /home/jishengchenmsu/.cache/torch/mmf/data/datasets/hateful_memes/defaults/images/\n",
        "!ls /home/jishengchenmsu/.cache/torch/mmf/data/datasets/hateful_memes/defaults/annotations\n",
        "\n",
        "# # check the number of images\n",
        "!ls /home/jishengchenmsu/.cache/torch/mmf/data/datasets/hateful_memes/defaults/images/img/ |wc -l\n",
        "print(\"Done\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data  img  img_ocr.zip\timg_raw.zip\n",
            "dev_seen.jsonl\t  test_seen.jsonl    train.jsonl\n",
            "dev_unseen.jsonl  test_unseen.jsonl\n",
            "12140\n",
            "Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PtN9i3bPh5rj"
      },
      "source": [
        "# Free up the disk by removing .zip, .tar files\n",
        "# !rm -rf /home/jishengchenmsu/.cache/torch/mmf/data/datasets/hateful_memes/defaults/images/img_ocr.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aJj5c7SlmWiH",
        "outputId": "1e3a1dc1-8757-4f05-b6eb-1fada264563b"
      },
      "source": [
        "# check the files under the cach folder\n",
        "!ls /home/jishengchenmsu/.cache/torch/mmf/data/datasets/hateful_memes/defaults/\n",
        "!ls /home/jishengchenmsu/.cache/torch/mmf/data/datasets/hateful_memes/defaults/images/\n",
        "!ls /home/jishengchenmsu/.cache/torch/mmf/data/datasets/hateful_memes/defaults/annotations\n",
        "\n",
        "# # check the number of images\n",
        "!ls /home/jishengchenmsu/.cache/torch/mmf/data/datasets/hateful_memes/defaults/images/img/ |wc -l"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "annotations  extras  extras.tar.gz  features  images\n",
            "data  img  img_ocr.zip\timg_raw.zip\n",
            "dev_seen.jsonl\t  test_seen.jsonl    train.jsonl\n",
            "dev_unseen.jsonl  test_unseen.jsonl\n",
            "12140\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wsFFVHWRhXK3",
        "outputId": "cf63b946-2a53-44a0-e440-9b22ac759a0a"
      },
      "source": [
        "# number of unique images in the dataset\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "annotation_dir = \"/home/jishengchenmsu/.cache/torch/mmf/data/datasets/hateful_memes/defaults/annotations\"\n",
        "img_dir = \"/home/jishengchenmsu/.cache/torch/mmf/data/datasets/hateful_memes/defaults/images/img/\"\n",
        "\n",
        "# Collect all the annotations (from Phase-2)\n",
        "train       = pd.read_json(f\"{annotation_dir}/train.jsonl\", lines=True)\n",
        "dev_seen    = pd.read_json(f\"{annotation_dir}/dev_seen.jsonl\", lines=True)\n",
        "dev_unseen  = pd.read_json(f\"{annotation_dir}/dev_unseen.jsonl\", lines=True)\n",
        "test_seen   = pd.read_json(f\"{annotation_dir}/test_seen.jsonl\", lines=True)\n",
        "test_unseen = pd.read_json(f\"{annotation_dir}/test_unseen.jsonl\", lines=True)\n",
        "\n",
        "# Create 2 sets: \n",
        "#   A set of strings, 'a': for all the image names,\n",
        "#   A set of lists, 'b': for all the image names in dataset, e.g. train, dev_seen, etc.\n",
        "a = os.listdir(f\"{img_dir}\")\n",
        "b = []\n",
        "for i in [train, dev_seen, dev_unseen, test_seen, test_unseen]:\n",
        "    b.append(list(i[\"img\"].str.split(\"/\").str.get(1)))\n",
        "\n",
        "set_mapping = ['train', 'dev_seen', 'dev_unseen', 'test_seen', 'test_unseen']\n",
        "total_size = 0\n",
        "print(\"#of images in: \")\n",
        "for idx, i in enumerate(b):\n",
        "    total_size += len(set(i))\n",
        "    print(f\"\\t'{set_mapping[idx]}'  \\t:\", len(set(i)))\n",
        "else:\n",
        "    print(f\"\\nIn total there are {total_size} images,\",\n",
        "          \"\\nBut the # of images in /img/ directory is: \", len(a))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "#of images in: \n",
            "\t'train'  \t: 8500\n",
            "\t'dev_seen'  \t: 500\n",
            "\t'dev_unseen'  \t: 540\n",
            "\t'test_seen'  \t: 1000\n",
            "\t'test_unseen'  \t: 2000\n",
            "\n",
            "In total there are 12540 images, \n",
            "But the # of images in /img/ directory is:  12140\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Cj3V6Dr2KJF"
      },
      "source": [
        "# extract image featuresï¼Œ intall packages and repos\n",
        "import os\n",
        "home = \"/home/jishengchenmsu\"\n",
        "os.environ['MKL_THREADING_LAYER'] = 'GNU'\n",
        "os.chdir(home)\n",
        "!git clone https://gitlab.com/vedanuj/vqa-maskrcnn-benchmark\n",
        "\n",
        "!pip install ninja yacs cython matplotlib\n",
        "\n",
        "os.chdir(os.path.join(home, \"vqa-maskrcnn-benchmark\"))\n",
        "!rm -rf build\n",
        "!python setup.py build develop\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NkZc6UYZC0IP",
        "outputId": "015ee34b-c615-43ba-d58a-a6f22e10db14"
      },
      "source": [
        "# install cv2\n",
        "!pip install opencv-python"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: opencv-python in /home/jishengchenmsu/anaconda3/lib/python3.8/site-packages (4.5.1.48)\r\n",
            "Requirement already satisfied: numpy>=1.17.3 in /home/jishengchenmsu/anaconda3/lib/python3.8/site-packages (from opencv-python) (1.19.2)\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aezPWQkd5XeD"
      },
      "source": [
        "import os\n",
        "os.chdir(os.path.join(home, \"mmf/tools/scripts/features/\"))\n",
        "out_folder = os.path.join(home, \"features_101/\")\n",
        "print(\"starting extracting\")\n",
        "!python extract_features_vmb.py --config_file \"https://dl.fbaipublicfiles.com/pythia/detectron_model/detectron_model.yaml\" \\\n",
        "                                --model_name \"X-101\" \\\n",
        "                                --output_folder $out_folder \\\n",
        "                                --image_dir \"/home/jishengchenmsu/.cache/torch/mmf/data/datasets/hateful_memes/defaults/images/img/\" \\\n",
        "                                --num_features 100 \\\n",
        "                                --start_index 0 \\\n",
        "                                --end_index 12140 \\\n",
        "                                # --exclude_list \"/content/exclude.txt\"\n",
        "                                # --feature_name \"fc6\" \\\n",
        "                                # --confidence_threshold 0. \\"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uRxQR1XXC0IR"
      },
      "source": [
        "# !ls /home/jishengchenmsu/features_101/ |wc -l\n",
        "!zip -r features_101.zip /home/jishengchenmsu/features_101"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0TfKQPSScXBq",
        "scrolled": true,
        "outputId": "a92796ab-c6dc-40dc-b985-85472bf76f13"
      },
      "source": [
        "\n",
        "# ****************** download feature data ********************\n",
        "os.chdir(home)\n",
        "\n",
        "# features after OCR (Maks RCNN + Resnet152)\n",
        "# !gdown https://drive.google.com/uc?id=13-VeoX4eYQH-PAlC5SQXO45bduBXMmri\n",
        "\n",
        "# features from 3rd place (no OCR, Maks RCNN + Resnet152)\n",
        "# !gdown https://drive.google.com/uc?id=1qlCkuzOVZJl8JRrfD-HcjWG12sQs3RYe\n",
        "\n",
        "# features after OCR (grid region extraction)\n",
        "!gdown https://drive.google.com/uc?id=17GXc6Zz03QCk82J3acEI3AWIVEPuTzpk"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=17GXc6Zz03QCk82J3acEI3AWIVEPuTzpk\n",
            "To: /home/jishengchenmsu/features_grid_extract.zip\n",
            "12.7MB [00:00, 79.4MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QwKPE7SjC0IS"
      },
      "source": [
        "# Unzip OCR feature (mask RCNN + Resnet152)\n",
        "# !unzip features_ocr.zip -d /home/jishengchenmsu/\n",
        "\n",
        "# unzip OCR feature (grid region extraction)\n",
        "!unzip features_grid_extract.zip -d /home/jishengchenmsu/features_grid_extract/"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KpZumWTcC0IU"
      },
      "source": [
        "# Free up the disk by removing .zip, .tar files\n",
        "# !rm -rf /home/jishengchenmsu/feature_ocr/features_ocr.zipcd "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lbd04gMJGOLK",
        "outputId": "844b17b0-3697-49b2-953a-01e3e0bbb042"
      },
      "source": [
        "# Check how many images we have in total\n",
        "# !ls /home/jishengchenmsu/features_ocr/ |wc -l\n",
        "# !ls /home/jishengchenmsu/features_grid_extract/hm2021/ |wc -l\n",
        "# !ls /home/jishengchenmsu/features_grid_extract/hm2021\n",
        "import numpy as np\n",
        "data = np.load(\"/home/jishengchenmsu/features_grid_extract/hm2021/01247.npy\", allow_pickle=True)\n",
        "data.item(0)\n",
        "data.item(0)[\"bbox\"].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4mQ6tlJvdScl"
      },
      "source": [
        "# ********************** Training ******************************* #\n",
        "import torch\n",
        "from torch.utils import tensorboard\n",
        "os.chdir(home)\n",
        "# feats_dir = os.path.join(home, \"features_grid_extract/hm2021/\")\n",
        "feats_dir = \"/home/jishengchenmsu/features_grid_extract/hm2021/\"\n",
        "# train_dir = os.path.join(home, \"train_500.jsonl\") # temporay train 500 images\n",
        "annotation_dir = \"hateful_memes/defaults/annotations/\"\n",
        "dev_unseen_dir = annotation_dir + \"dev_unseen.jsonl\"\n",
        "test_unseen_dir = annotation_dir + \"test_unseen.jsonl\"\n",
        "train_dir = annotation_dir + \"train.jsonl\"\n",
        "ckpt_dir = os.path.join(home, \"model6/best.ckpt\")\n",
        "\n",
        "!mmf_run config=\"projects/visual_bert/configs/hateful_memes/from_coco.yaml\" \\\n",
        "        model=\"visual_bert\" \\\n",
        "        dataset=hateful_memes \\\n",
        "        run_type=train_val \\\n",
        "        checkpoint.resume=True\\\n",
        "        checkpoint.resume_file=$ckpt_dir\\\n",
        "        checkpoint.max_to_keep=1 \\\n",
        "        checkpoint.resume_zoo=visual_bert.pretrained.cc.full \\\n",
        "        training.tensorboard=True \\\n",
        "        training.checkpoint_interval=100 \\\n",
        "        training.evaluation_interval=100 \\\n",
        "        training.max_updates=4000 \\\n",
        "        training.log_interval=500 \\\n",
        "        dataset_config.hateful_memes.max_features=100 \\\n",
        "        dataset_config.hateful_memes.annotations.train[0]=$train_dir \\\n",
        "        dataset_config.hateful_memes.annotations.val[0]=$dev_unseen_dir \\\n",
        "        dataset_config.hateful_memes.annotations.test[0]=$test_unseen_dir \\\n",
        "        dataset_config.hateful_memes.features.train[0]=$feats_dir \\\n",
        "        dataset_config.hateful_memes.features.val[0]=$feats_dir \\\n",
        "        dataset_config.hateful_memes.features.test[0]=$feats_dir \\\n",
        "        training.lr_ratio=0.01 \\\n",
        "        training.use_warmup=True \\\n",
        "        training.batch_size=32 \\\n",
        "        optimizer.params.lr=5.0e-05 \\\n",
        "        env.save_dir=./model6 \\\n",
        "        env.tensorboard_logdir=logs/fit/model6\n",
        "\n",
        "\n",
        "# ********************** Training ******************************* #\n",
        "# os.environ['MKL_THREADING_LAYER'] = 'GNU'\n",
        "# os.chdir(home)\n",
        "# ckpt_dir = \"home/jishengchenmsu/v0_500/best.ckpt\"\n",
        "# feats_dir = os.path.join(home, \"features_ocr\")\n",
        "# train_dir = os.path.join(home, \"train_500.jsonl\")\n",
        "# annotation_dir = \"hateful_memes/defaults/annotations/\"\n",
        "# dev_unseen_dir = annotation_dir + \"dev_unseen.jsonl\"\n",
        "# test_unseen_dir = annotation_dir + \"test_unseen.jsonl\"\n",
        "\n",
        "# !mmf_run config=\"projects/visual_bert/configs/hateful_memes/from_coco.yaml\" \\\n",
        "#         model=\"visual_bert\" \\\n",
        "#         dataset=hateful_memes \\\n",
        "#         run_type=train_val \\\n",
        "#         checkpoint.resume_file=$ckpt_dir \\\n",
        "#         checkpoint.reset.optimizer=True \\\n",
        "#         checkpoint.resume=True\\\n",
        "#         checkpoint.max_to_keep=1 \\\n",
        "#         checkpoint.resume_zoo=visual_bert.pretrained.cc.full \\\n",
        "#         training.tensorboard=True \\\n",
        "#         training.checkpoint_interval=50 \\\n",
        "#         training.evaluation_interval=50 \\\n",
        "#         training.max_updates=500 \\\n",
        "#         training.log_interval=100 \\\n",
        "#         dataset_config.hateful_memes.max_features=100 \\\n",
        "#         dataset_config.hateful_memes.annotations.train[0]=$train_dir \\\n",
        "#         dataset_config.hateful_memes.annotations.val[0]=$dev_unseen_dir \\\n",
        "#         dataset_config.hateful_memes.annotations.test[0]=$test_unseen_dir \\\n",
        "#         dataset_config.hateful_memes.features.train[0]=$feats_dir \\\n",
        "#         dataset_config.hateful_memes.features.val[0]=$feats_dir \\\n",
        "#         dataset_config.hateful_memes.features.test[0]=$feats_dir \\\n",
        "#         training.lr_ratio=0.3 \\\n",
        "#         training.use_warmup=True \\\n",
        "#         training.batch_size=32 \\\n",
        "#         optimizer.params.lr=5.0e-05 \\\n",
        "#         env.save_dir=./v0_500 \\\n",
        "#         env.tensorboard_logdir=logs/fit/v0_500\\"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e1kpt1wza9qK"
      },
      "source": [
        "# import torch\n",
        "# # PATH = './drive/My Drive/checkpoint.pth'\n",
        "# PATH = '/content/drive/MyDrive/checkpoint.pth'\n",
        "# torch.save(model.state_dict(), PATH)\n",
        "# files.download(PATH)\n",
        "# state_dict = torch.load(PATH)\n",
        "# print(state_dict.keys())\n",
        "# model.load_state_dict(state_dict)\n",
        "\n",
        "# ********************* baseline predicition **********************\n",
        "import os\n",
        "os.chdir(home)\n",
        "feats_dir = os.path.join(home, \"features_ocr\")\n",
        "annotation_dir = \"hateful_memes/defaults/annotations/\"\n",
        "dev_unseen_dir = annotation_dir + \"dev_unseen.jsonl\"\n",
        "test_unseen_dir = annotation_dir + \"test_unseen.jsonl\"\n",
        "\n",
        "\n",
        "!mmf_predict config=projects/hateful_memes/configs/visual_bert/from_coco.yaml \\\n",
        "                model=visual_bert\\\n",
        "                dataset=hateful_memes\\\n",
        "                run_type=test\\\n",
        "                checkpoint.resume_zoo=visual_bert.finetuned.hateful_memes.from_coco\\\n",
        "                dataset_config.hateful_memes.annotations.val[0]=$dev_unseen_dir\\\n",
        "                dataset_config.hateful_memes.annotations.test[0]=$test_unseen_dir\\\n",
        "                dataset_config.hateful_memes.features.train[0]=$feats_dir\\\n",
        "                dataset_config.hateful_memes.features.val[0]=$feats_dir\\\n",
        "                dataset_config.hateful_memes.features.test[0]=$feats_dir"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8HZUt_WqeqeO"
      },
      "source": [
        "# # Visualize losses/accuracy via Tensorboard\n",
        "# # Load the TensorBoard notebook extension\n",
        "# %load_ext tensorboard\n",
        "# %tensorboard --logdir logs/fit"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r5irZh2EgA1l"
      },
      "source": [
        "# prediction (test_unseen.jsonl)\n",
        "#************ self-defined model prediction *************************\n",
        "import os\n",
        "# # where checkpoint is\n",
        "os.chdir(home)\n",
        "ckpt_dir = os.path.join(home, \"best.ckpt\")\n",
        "feats_dir = os.path.join(home, \"features_ocr\")\n",
        "annotation_dir = \"hateful_memes/defaults/annotations/\"\n",
        "dev_unseen_dir = annotation_dir + \"dev_unseen.jsonl\"\n",
        "test_unseen_dir = annotation_dir + \"test_unseen.jsonl\"\n",
        "\n",
        "\n",
        "!mmf_predict config=\"projects/visual_bert/configs/hateful_memes/defaults.yaml\"\\\n",
        "     model=\"visual_bert\"\\\n",
        "     dataset=hateful_memes\\\n",
        "     run_type=test\\\n",
        "     checkpoint.resume_file=$ckpt_dir\\\n",
        "     checkpoint.reset.optimizer=True\\\n",
        "     dataset_config.hateful_memes.annotations.val[0]=$dev_unseen_dir\\\n",
        "     dataset_config.hateful_memes.annotations.test[0]=$test_unseen_dir\\\n",
        "     dataset_config.hateful_memes.features.train[0]=$feats_dir\\\n",
        "     dataset_config.hateful_memes.features.val[0]=$feats_dir\\\n",
        "     dataset_config.hateful_memes.features.test[0]=$feats_dir"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BhbpzxAxa0rD"
      },
      "source": [
        "# # Test pretrained model\n",
        "# import matplotlib.pyplot as plt\n",
        "# import requests\n",
        "\n",
        "# from PIL import Image\n",
        "\n",
        "# from mmf.models.mmbt import MMBT\n",
        "\n",
        "# model = MMBT.from_pretrained(\"mmbt.hateful_memes.images\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xcO4Qe71a2xn"
      },
      "source": [
        "# image_url = \"https://i.imgur.com/tEcsk5q.jpg\" #@param {type:\"string\"}\n",
        "# text = \"look how many people love you\" #@param {type: \"string\"}\n",
        "# output = model.classify(image_url, text)\n",
        "# plt.imshow(Image.open(requests.get(image_url, stream=True).raw))\n",
        "# plt.axis(\"off\")\n",
        "# plt.show()\n",
        "# hateful = \"Yes\" if output[\"label\"] == 1 else \"No\"\n",
        "# print(\"Hateful as per the model?\", hateful)\n",
        "# print(f\"Model's confidence: {output['confidence'] * 100:.3f}%\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}